{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:25:34.178383Z",
     "start_time": "2024-12-01T22:25:29.919940Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from ipywidgets.widgets import HBox\n",
    "\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:25:34.183720Z",
     "start_time": "2024-12-01T22:25:34.181297Z"
    }
   },
   "source": [
    "ROOT_PATH = './'\n",
    "DRIVE_PATH = 'Colab/TimeSeries-TP'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive, output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:26.976443Z",
     "start_time": "2024-12-01T22:30:26.974191Z"
    }
   },
   "source": [
    "RANDOM_SEED = 1984\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TOTAL_EPOCHS = 500\n",
    "\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-8\n",
    "AMSGRAD = False\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "WARMUP_RATIO = 0.05\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "EVAL_K = 10\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = 'cpu'\n",
    "\n",
    "# Use NVIDIA GPU if available\n",
    "if cuda.is_available():\n",
    "    PYTORCH_DEVICE = 'cuda'\n",
    "\n",
    "# Use Apple Metal backend if available\n",
    "if torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"Your device supports MPS but it is not installed. Checkout https://developer.apple.com/metal/pytorch/\")\n",
    "    else:\n",
    "        PYTORCH_DEVICE = 'mps'\n",
    "\n",
    "\n",
    "print (f\"Using {PYTORCH_DEVICE} device for PyTorch\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device for PyTorch\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:28.765733Z",
     "start_time": "2024-12-01T22:30:28.762308Z"
    }
   },
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.mps.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:08.604447Z",
     "start_time": "2024-12-01T22:25:34.481200Z"
    }
   },
   "source": [
    "DATA_DIR = \"./data/ltafdb-processed\"\n",
    "all_data = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for file in tqdm(files, desc=\"Loading Records\", unit=\"Records\"):\n",
    "        if file.endswith(\".pqt.zstd\"):\n",
    "                all_data.append(pl.read_parquet(os.path.join(root, file)))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading Records:   0%|          | 0/84 [00:00<?, ?Records/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "095a678d3c844187899022cf89c7a1e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:09.101138Z",
     "start_time": "2024-12-01T22:26:08.949137Z"
    }
   },
   "source": [
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "test_data, validation_data = train_test_split(test_data, test_size=0.5, random_state=RANDOM_SEED)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:09.273015Z",
     "start_time": "2024-12-01T22:26:09.236279Z"
    }
   },
   "source": [
    "class WindowedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframes: list[pl.DataFrame],\n",
    "        window_size: int,\n",
    "        stride: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframes\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "\n",
    "        self.window_count = [\n",
    "            (len(df) - window_size) // stride\n",
    "            for df in self.dataframe\n",
    "        ]\n",
    "        self.len = sum(self.window_count)\n",
    "\n",
    "        self.signals = [df['signal'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.labels = [df['is_abnormal'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.starts = [df['start'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.ends = [df['end'].explode().to_numpy() for df in self.dataframe]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        df_idx = 0\n",
    "        while idx >= self.window_count[df_idx]:\n",
    "            idx -= self.window_count[df_idx]\n",
    "            df_idx += 1\n",
    "        \n",
    "        start = idx * self.stride\n",
    "        end = start + self.window_size\n",
    "\n",
    "        series = self.signals[df_idx][self.starts[df_idx][start]:self.ends[df_idx][end-1]]\n",
    "        label = np.any(self.labels[df_idx][start:end])\n",
    "        \n",
    "        return series, label"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:37.429256Z",
     "start_time": "2024-12-01T22:26:09.297729Z"
    }
   },
   "source": [
    "train_dataset = WindowedDataset(train_data, window_size=100, stride=1)\n",
    "validation_dataset = WindowedDataset(validation_data, window_size=100, stride=1)\n",
    "test_dataset = WindowedDataset(test_data, window_size=100, stride=1)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.045871Z",
     "start_time": "2024-12-01T22:27:38.035318Z"
    }
   },
   "source": [
    "print(f\"Training dataset size (windows): {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size (windows): {len(validation_dataset)}\")\n",
    "print(f\"Test dataset size (windows): {len(test_dataset)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size (windows): 7431368\n",
      "Validation dataset size (windows): 810401\n",
      "Test dataset size (windows): 805383\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.512026Z",
     "start_time": "2024-12-01T22:27:38.510476Z"
    }
   },
   "source": [
    "# pos_count = 0\n",
    "# for _, label in tqdm(train_dataset):\n",
    "#     if label:\n",
    "#         pos_count += 1\n",
    "# print(f\"Positive ratio: {pos_count/len(train_dataset):2%}\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.974969Z",
     "start_time": "2024-12-01T22:27:38.845492Z"
    }
   },
   "source": [
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, n_features=1, lstm_units=200, lstm_layers=1, lstm_dropout=0, dense_units=50, dense_dropout=0.1):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.lstm = nn.LSTM(n_features, lstm_units, num_layers=lstm_layers, batch_first=True, bidirectional=True, dropout=lstm_dropout)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(2*lstm_units, dense_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dense_dropout)\n",
    "        self.output = nn.Linear(dense_units, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:35.478799Z",
     "start_time": "2024-12-01T22:30:35.465073Z"
    }
   },
   "source": [
    "def collate_fn(data: list[tuple[np.ndarray, bool]]):\n",
    "    seq_lengths = torch.tensor([len(d[0]) for d in data], dtype=torch.long)\n",
    "    seq_tensor = torch.zeros((len(data), seq_lengths.max()), dtype=torch.float32)\n",
    "    for idx, (seq, seq_len) in enumerate(zip(data, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.tensor(seq[0], dtype=torch.float32)\n",
    "\n",
    "    return seq_tensor.unsqueeze(-1), torch.tensor([d[1] for d in data], dtype=torch.float32)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:37.545609Z",
     "start_time": "2024-12-01T22:30:37.530339Z"
    }
   },
   "source": [
    "model = ECGModel()\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2), eps=EPS, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, total_steps=TOTAL_EPOCHS * len(train_dataloader), \n",
    "    pct_start=WARMUP_RATIO, cycle_momentum=False, anneal_strategy='linear')"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:32:11.329381Z",
     "start_time": "2024-12-01T22:32:11.326113Z"
    }
   },
   "source": [
    "def train(\n",
    "    model: ECGModel,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler._LRScheduler | None,\n",
    "    criterion: nn.modules.loss._Loss,\n",
    "    train_loader: DataLoader,\n",
    "    validation_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "):\n",
    "    loss_history = []\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Batch\", leave=False, total=len(train_loader)):\n",
    "            model.zero_grad()\n",
    "\n",
    "\n",
    "            inputs, targets = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            steps += 1\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} loss: {epoch_loss / steps}\")\n",
    "        loss_history.append(epoch_loss / steps)\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "# def validate(\n",
    "#     model: ECGModel,\n",
    "#     criterion: nn.modules.loss._Loss,\n",
    "#     validation_loader: DataLoader,\n",
    "#     device: str,\n",
    "# ):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         loss = 0\n",
    "#         for batch in validation_loader:\n",
    "#             inputs, targets = batch\n",
    "#             inputs = inputs.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             loss += criterion(outputs, targets).item()\n",
    "        \n",
    "#         return loss / len(validation_loader)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:35:03.197974Z",
     "start_time": "2024-12-01T22:32:13.610718Z"
    }
   },
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    loss_history = train(model, optimizer, scheduler, criterion, train_dataloader, validation_dataloader, TOTAL_EPOCHS, PYTORCH_DEVICE)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8dc7e33bd5e4b42a317e5c042d3e0c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batch:   0%|          | 0/928921 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42c2798c456446198a72491ecceee49f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[1;32m      2\u001B[0m     warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     loss_history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTOTAL_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPYTORCH_DEVICE\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 27\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, optimizer, scheduler, criterion, train_loader, validation_loader, epochs, device)\u001B[0m\n\u001B[1;32m     24\u001B[0m inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     25\u001B[0m targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 27\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     28\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n\u001B[1;32m     30\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[11], line 13\u001B[0m, in \u001B[0;36mECGModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 13\u001B[0m     x, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     15\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(x)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1123\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m   1120\u001B[0m         hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[1;32m   1122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1123\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1132\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1135\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   1137\u001B[0m         batch_sizes,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional,\n\u001B[1;32m   1145\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:32:07.116205Z",
     "start_time": "2024-12-01T22:32:06.759436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ],
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
