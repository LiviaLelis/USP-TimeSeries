{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:25:34.178383Z",
     "start_time": "2024-12-01T22:25:29.919940Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from ipywidgets.widgets import HBox\n",
    "\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:25:34.183720Z",
     "start_time": "2024-12-01T22:25:34.181297Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = './'\n",
    "DRIVE_PATH = 'Colab/TimeSeries-TP'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive, output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:26.976443Z",
     "start_time": "2024-12-01T22:30:26.974191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device for PyTorch\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1984\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "TOTAL_EPOCHS = 10\n",
    "\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-8\n",
    "AMSGRAD = False\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "WARMUP_RATIO = 0.05\n",
    "LEARNING_RATE = 0.04\n",
    "\n",
    "\n",
    "EVAL_K = 10\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = 'cpu'\n",
    "\n",
    "# Use NVIDIA GPU if available\n",
    "if cuda.is_available():\n",
    "    PYTORCH_DEVICE = 'cuda'\n",
    "\n",
    "# Use Apple Metal backend if available\n",
    "if torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"Your device supports MPS but it is not installed. Checkout https://developer.apple.com/metal/pytorch/\")\n",
    "    else:\n",
    "        PYTORCH_DEVICE = 'mps'\n",
    "\n",
    "\n",
    "print (f\"Using {PYTORCH_DEVICE} device for PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:28.765733Z",
     "start_time": "2024-12-01T22:30:28.762308Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.mps.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:08.604447Z",
     "start_time": "2024-12-01T22:25:34.481200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ba0df269c14e90979f3b476a0622f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Records:   0%|          | 0/84 [00:00<?, ?Records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = \"./data/ltafdb-processed\"\n",
    "all_data = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for file in tqdm(files, desc=\"Loading Records\", unit=\"Records\"):\n",
    "        if file.endswith(\".pqt.zstd\"):\n",
    "                all_data.append(pl.read_parquet(os.path.join(root, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:09.101138Z",
     "start_time": "2024-12-01T22:26:08.949137Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(all_data[:10], test_size=0.2, random_state=RANDOM_SEED)\n",
    "test_data, validation_data = train_test_split(test_data, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:26:09.273015Z",
     "start_time": "2024-12-01T22:26:09.236279Z"
    }
   },
   "outputs": [],
   "source": [
    "class WindowedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframes: list[pl.DataFrame],\n",
    "        window_size: int,\n",
    "        stride: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframes\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "\n",
    "        self.window_count = [\n",
    "            (len(df) - window_size) // stride\n",
    "            for df in self.dataframe\n",
    "        ]\n",
    "        self.len = sum(self.window_count)\n",
    "\n",
    "        self.signals = [df['signal'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.labels = [df['is_abnormal'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.starts = [df['start'].explode().to_numpy() for df in self.dataframe]\n",
    "        self.ends = [df['end'].explode().to_numpy() for df in self.dataframe]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        df_idx = 0\n",
    "        while idx >= self.window_count[df_idx]:\n",
    "            idx -= self.window_count[df_idx]\n",
    "            df_idx += 1\n",
    "        \n",
    "        start = idx * self.stride\n",
    "        end = start + self.window_size\n",
    "\n",
    "        series = self.signals[df_idx][self.starts[df_idx][start]:self.ends[df_idx][end-1]]\n",
    "        label = np.any(self.labels[df_idx][start:end])\n",
    "        \n",
    "        return series, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:37.429256Z",
     "start_time": "2024-12-01T22:26:09.297729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = WindowedDataset(train_data, window_size=20, stride=1)\n",
    "validation_dataset = WindowedDataset(validation_data, window_size=20, stride=1)\n",
    "test_dataset = WindowedDataset(test_data, window_size=20, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.045871Z",
     "start_time": "2024-12-01T22:27:38.035318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size (windows): 814556\n",
      "Validation dataset size (windows): 109604\n",
      "Test dataset size (windows): 114454\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size (windows): {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size (windows): {len(validation_dataset)}\")\n",
    "print(f\"Test dataset size (windows): {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.512026Z",
     "start_time": "2024-12-01T22:27:38.510476Z"
    }
   },
   "outputs": [],
   "source": [
    "# pos_count = 0\n",
    "# for _, label in tqdm(train_dataset):\n",
    "#     if label:\n",
    "#         pos_count += 1\n",
    "# print(f\"Positive ratio: {pos_count/len(train_dataset):2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:27:38.974969Z",
     "start_time": "2024-12-01T22:27:38.845492Z"
    }
   },
   "outputs": [],
   "source": [
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, n_features=1, lstm_units=200, lstm_layers=1, lstm_dropout=0, dense_units=50, dense_dropout=0.1):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.lstm = nn.LSTM(n_features, lstm_units, num_layers=lstm_layers, batch_first=True, bidirectional=True, dropout=lstm_dropout)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(2*lstm_units, dense_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dense_dropout)\n",
    "        self.output = nn.Linear(dense_units, 1)\n",
    "\n",
    "    def forward(self, seq, seq_len):\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(seq, seq_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        seq, _ = self.lstm(packed_seq)\n",
    "        seq, _ = nn.utils.rnn.pad_packed_sequence(seq, batch_first=True)\n",
    "        seq = seq.permute(0, 2, 1)\n",
    "        seq = self.pool(seq).squeeze(-1)\n",
    "        seq = self.fc1(seq)\n",
    "        seq = self.relu(seq)\n",
    "        seq = self.dropout(seq)\n",
    "        seq = self.output(seq)\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:35.478799Z",
     "start_time": "2024-12-01T22:30:35.465073Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(data: list[tuple[np.ndarray, bool]]):\n",
    "    seq_lengths = torch.tensor([len(d[0]) for d in data], dtype=torch.long)\n",
    "    padded_seqs = torch.nn.utils.rnn.pad_sequence([torch.tensor(d[0], dtype=torch.float32) for d in data], batch_first=True, padding_value=0.0)\n",
    "\n",
    "    return padded_seqs.unsqueeze(-1), seq_lengths, torch.tensor([d[1] for d in data], dtype=torch.float32)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:30:37.545609Z",
     "start_time": "2024-12-01T22:30:37.530339Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ECGModel()\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2), eps=EPS, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LEARNING_RATE, total_steps=TOTAL_EPOCHS * len(train_dataloader), \n",
    "    pct_start=WARMUP_RATIO, cycle_momentum=False, anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:32:11.329381Z",
     "start_time": "2024-12-01T22:32:11.326113Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: ECGModel,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler._LRScheduler | None,\n",
    "    criterion: nn.modules.loss._Loss,\n",
    "    train_loader: DataLoader,\n",
    "    validation_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "):\n",
    "    loss_history = []\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Batch\", leave=False, total=len(train_loader)):\n",
    "            model.zero_grad()\n",
    "\n",
    "\n",
    "            inputs, seq_len, targets = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs, seq_len).squeeze(1)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            steps += 1\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} loss: {epoch_loss / steps}\")\n",
    "        loss_history.append(epoch_loss / steps)\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "# def validate(\n",
    "#     model: ECGModel,\n",
    "#     criterion: nn.modules.loss._Loss,\n",
    "#     validation_loader: DataLoader,\n",
    "#     device: str,\n",
    "# ):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         loss = 0\n",
    "#         for batch in validation_loader:\n",
    "#             inputs, targets = batch\n",
    "#             inputs = inputs.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             loss += criterion(outputs, targets).item()\n",
    "        \n",
    "#         return loss / len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:35:03.197974Z",
     "start_time": "2024-12-01T22:32:13.610718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d47a7261f5b43789a55f87f57cc3f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44e076c9d6648b0930dddcc4218307f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/6364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m      2\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOTAL_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPYTORCH_DEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, criterion, train_loader, validation_loader, epochs, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs, seq_len)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.micromamba/envs/timeseries-tp/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    loss_history = train(model, optimizer, scheduler, criterion, train_dataloader, validation_dataloader, TOTAL_EPOCHS, PYTORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:32:07.116205Z",
     "start_time": "2024-12-01T22:32:06.759436Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
